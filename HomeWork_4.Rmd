---
title: "HomeWork_4"
author: "aa2569"
date: "3/4/2023"
output: html_document
---
  
```{r}
library(cluster)
library(readr)
library(factoextra)
library(magrittr)
library(NbClust)
```

## College Dataset

```{r}
clg11 <- read_csv("/Users/ajayvishnu/Desktop/RUTGERS/Spring 2023/Multivariate Analysis/Datasets/College_Data.csv")
clg21 <- data.frame(clg11, row.names = 1)

matstd.clg21 <- scale(clg21)

# Creating a (Euclidean) distance matrix of the standardized data 
dist.clg21 <- dist(matstd.clg21, method="euclidean")

# Invoking hclust command (cluster analysis by single linkage method)      
clusclg21.nn <- hclust(dist.clg21, method = "single") 

# Plotting vertical dendrogram      
# create extra margin room in the dendrogram, on the bottom (Canine species' labels)
#par(mar=c(6, 4, 4, 2) + 0.1)
plot(as.dendrogram(clusclg21.nn),ylab="Distance between Colleges",ylim=c(0,2.5),main="Dendrogram of all Colleges")
```

* The plot looks very messy as there are 700+ colleges in the dataset. 
* For better analysis, only 30 colleges have been selected for further analysis.

## Analysis on 30 selected colleges

```{r}
clg1 <- read_csv("/Users/ajayvishnu/Desktop/RUTGERS/Spring 2023/Multivariate Analysis/Datasets/College_Data_cleaned.csv")
clg <- data.frame(clg1, row.names = 1)
attach(clg)
str(clg)

matstd.clg <- scale(clg)

# Creating a (Euclidean) distance matrix of the standardized data 
dist.clg <- dist(matstd.clg, method="euclidean")

# Invoking hclust command (cluster analysis by single linkage method)      
clusclg.nn <- hclust(dist.clg, method = "single") 

# Plotting vertical dendrogram      
# create extra margin room in the dendrogram, on the bottom (Canine species' labels)
#par(mar=c(6, 4, 4, 2) + 0.1)
plot(as.dendrogram(clusclg.nn),ylab="Distance between Colleges",ylim=c(0,5.5),main="Dendrogram of 30 selected Colleges")
```

### Horizontal Dendogram

```{r}
plot(as.dendrogram(clusclg.nn), xlab= "Distance between Colleges", xlim=c(5.5,0),
     horiz = TRUE,main="Dendrogram of 30 selected Colleges")
```

### Using Agnes Function

```{r}
# Agnes function allows us to select option for data standardization, the distance measure and clustering algorithm in one single function

(agn.clg <- agnes(clg, metric="euclidean", stand=TRUE, method = "single"))

#  Description of cluster merging
agn.clg$merge

plot(as.dendrogram(agn.clg), xlab= "Distance between Colleges",xlim=c(8,0),
     horiz = TRUE,main="Dendrogram")
```

* The Agnes function

### Interactive Plots

```{r}
plot(agn.clg, which.plots=1)

plot(agn.clg, which.plots=2)
```

## K-Means Clustering

### 2 clusters

```{r}
matstd.clg <- scale(clg)
# K-means, k=2, 3, 4, 5, 6
# Centers (k's) are numbers thus, 10 random sets are chosen

(kmeans2.clg <- kmeans(matstd.clg,2,nstart = 10))
```

```{r}
# Computing the percentage of variation accounted for. Two clusters
perc.var.2 <- round(100*(1 - kmeans2.clg$betweenss/kmeans2.clg$totss),1)
names(perc.var.2) <- "Perc. 2 clus"
perc.var.2
```

### 3 clusters

```{r}
# Computing the percentage of variation accounted for. Three clusters
(kmeans3.clg <- kmeans(matstd.clg,3,nstart = 10))
```

```{r}
perc.var.3 <- round(100*(1 - kmeans3.clg$betweenss/kmeans3.clg$totss),1)
names(perc.var.3) <- "Perc. 3 clus"
perc.var.3
```

### 4 clusters

```{r}
# Computing the percentage of variation accounted for. Four clusters
(kmeans4.clg <- kmeans(matstd.clg,4,nstart = 10))
```

```{r}
perc.var.4 <- round(100*(1 - kmeans4.clg$betweenss/kmeans4.clg$totss),1)
names(perc.var.4) <- "Perc. 4 clus"
perc.var.4
```

### 5 clusters

```{r}
# Computing the percentage of variation accounted for. Five clusters
(kmeans5.clg <- kmeans(matstd.clg,5,nstart = 10))
```

```{r}
perc.var.5 <- round(100*(1 - kmeans5.clg$betweenss/kmeans5.clg$totss),1)
names(perc.var.5) <- "Perc. 5 clus"
perc.var.5
```

### 6 clusters

```{r}
# Computing the percentage of variation accounted for. Six clusters
(kmeans6.clg <- kmeans(matstd.clg,6,nstart = 10))
```

```{r}
perc.var.6 <- round(100*(1 - kmeans6.clg$betweenss/kmeans6.clg$totss),1)
names(perc.var.6) <- "Perc. 6 clus"
perc.var.6
```

## Variance List and plot

```{r}
Variance_List <- c(perc.var.2,perc.var.3,perc.var.4,perc.var.5,perc.var.6)

Variance_List

plot(Variance_List)
```

```{r}
# Saving four k-means clusters in a list
clus1 <- matrix(names(kmeans4.clg$cluster[kmeans4.clg$cluster == 1]), 
                ncol=1, nrow=length(kmeans4.clg$cluster[kmeans4.clg$cluster == 1]))
colnames(clus1) <- "Cluster 1"
clus2 <- matrix(names(kmeans4.clg$cluster[kmeans4.clg$cluster == 2]), 
                ncol=1, nrow=length(kmeans4.clg$cluster[kmeans4.clg$cluster == 2]))
colnames(clus2) <- "Cluster 2"
clus3 <- matrix(names(kmeans4.clg$cluster[kmeans4.clg$cluster == 3]), 
                ncol=1, nrow=length(kmeans4.clg$cluster[kmeans4.clg$cluster == 3]))
colnames(clus3) <- "Cluster 3"
clus4 <- matrix(names(kmeans4.clg$cluster[kmeans4.clg$cluster == 4]), 
                ncol=1, nrow=length(kmeans4.clg$cluster[kmeans4.clg$cluster == 4]))
colnames(clus4) <- "Cluster 4"
list(clus1,clus2,clus3,clus4)
```

## VISUALISATIONS

```{r}
res.dist <- get_dist(clg, stand = TRUE, method = "pearson")

# Understand the Distance Between States
fviz_dist(res.dist, 
          gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
# Lets Try to Find the Optimal Distance
fviz_nbclust(clg, kmeans, method = "gap_stat")
```

* It tells us that having three clusters is optimal.

```{r}
set.seed(123)
km.res <- kmeans(clg, 3, nstart = 25)
# Visualize
fviz_cluster(km.res, data = clg,
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal())
```

### For Outliers, we use the following:

```{r}
pam.res <- pam(clg, 3)
# Visualize
fviz_cluster(pam.res)
```

## Hierarchial Clusiering

```{r}
res.hc <- clg %>% scale() %>% dist(method = "euclidean") %>%
  hclust(method = "ward.D2")

fviz_dend(res.hc, k = 4, # Cut in four groups
          cex = 0.5, # label size
          k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
          color_labels_by_k = TRUE, # color labels by groups
          rect = TRUE # Add rectangle around groups
          )
```

* We have used 4 clusters in this case.

## Optimal Clusters

```{r}
# Lets see what the optimal numbers of clusers are
# Compute
res.nbclust <- clg %>% scale() %>% NbClust(distance = "euclidean", min.nc = 2, max.nc = 10, method = "complete", index ="all") 
```

```{r}
# Visualize
fviz_nbclust <- function (x, FUNcluster = NULL, method = c("silhouette", "wss", 
                                           "gap_stat"), diss = NULL, k.max = 10, nboot = 100, verbose = interactive(), 
          barfill = "steelblue", barcolor = "steelblue", linecolor = "steelblue", 
          print.summary = TRUE, ...) 
{
  set.seed(123)
  if (k.max < 2) 
    stop("k.max must bet > = 2")
  method = match.arg(method)
  if (!inherits(x, c("data.frame", "matrix")) & !("Best.nc" %in% 
                                                  names(x))) 
    stop("x should be an object of class matrix/data.frame or ", 
         "an object created by the function NbClust() [NbClust package].")
  if (inherits(x, "list") & "Best.nc" %in% names(x)) {
    best_nc <- x$Best.nc
    if (any(class(best_nc) == "numeric") ) 
      print(best_nc)
    else if (any(class(best_nc) == "matrix") )
      .viz_NbClust(x, print.summary, barfill, barcolor)
  }
  else if (is.null(FUNcluster)) 
    stop("The argument FUNcluster is required. ", "Possible values are kmeans, pam, hcut, clara, ...")
  else if (!is.function(FUNcluster)) {
    stop("The argument FUNcluster should be a function. ", 
         "Check if you're not overriding the specified function name somewhere.")
  }
  else if (method %in% c("silhouette", "wss")) {
    if (is.data.frame(x)) 
      x <- as.matrix(x)
    if (is.null(diss)) 
      diss <- stats::dist(x)
    v <- rep(0, k.max)
    if (method == "silhouette") {
      for (i in 2:k.max) {
        clust <- FUNcluster(x, i, ...)
        v[i] <- .get_ave_sil_width(diss, clust$cluster)
      }
    }
    else if (method == "wss") {
      for (i in 1:k.max) {
        clust <- FUNcluster(x, i, ...)
        v[i] <- .get_withinSS(diss, clust$cluster)
      }
    }
    df <- data.frame(clusters = as.factor(1:k.max), y = v, 
                     stringsAsFactors = TRUE)
    ylab <- "Total Within Sum of Square"
    if (method == "silhouette") 
      ylab <- "Average silhouette width"
    p <- ggpubr::ggline(df, x = "clusters", y = "y", group = 1, 
                        color = linecolor, ylab = ylab, xlab = "Number of clusters k", 
                        main = "Optimal number of clusters")
    if (method == "silhouette") 
      p <- p + geom_vline(xintercept = which.max(v), linetype = 2, 
                          color = linecolor)
    return(p)
  }
  else if (method == "gap_stat") {
    extra_args <- list(...)
    gap_stat <- cluster::clusGap(x, FUNcluster, K.max = k.max, 
                                 B = nboot, verbose = verbose, ...)
    if (!is.null(extra_args$maxSE)) 
      maxSE <- extra_args$maxSE
    else maxSE <- list(method = "firstSEmax", SE.factor = 1)
    p <- fviz_gap_stat(gap_stat, linecolor = linecolor, 
                       maxSE = maxSE)
    return(p)
  }
}

.viz_NbClust <- function (x, print.summary = TRUE, barfill = "steelblue", 
          barcolor = "steelblue") 
{
  best_nc <- x$Best.nc
  if (any(class(best_nc) == "numeric") )
    print(best_nc)
  else if (any(class(best_nc) == "matrix") ) {
    best_nc <- as.data.frame(t(best_nc), stringsAsFactors = TRUE)
    best_nc$Number_clusters <- as.factor(best_nc$Number_clusters)
    if (print.summary) {
      ss <- summary(best_nc$Number_clusters)
      cat("Among all indices: \n===================\n")
      for (i in 1:length(ss)) {
        cat("*", ss[i], "proposed ", names(ss)[i], 
            "as the best number of clusters\n")
      }
      cat("\nConclusion\n=========================\n")
      cat("* According to the majority rule, the best number of clusters is ", 
          names(which.max(ss)), ".\n\n")
    }
    df <- data.frame(Number_clusters = names(ss), freq = ss, 
                     stringsAsFactors = TRUE)
    p <- ggpubr::ggbarplot(df, x = "Number_clusters", 
                           y = "freq", fill = barfill, color = barcolor) + 
      labs(x = "Number of clusters k", y = "Frequency among all indices", 
           title = paste0("Optimal number of clusters - k = ", 
                          names(which.max(ss))))
    return(p)
  }
}
# assign them to the factoextra namespace
environment(fviz_nbclust) <- asNamespace("factoextra")
assignInNamespace("fviz_nbclust",fviz_nbclust,"factoextra")
environment(.viz_NbClust) <- asNamespace("factoextra")
assignInNamespace(".viz_NbClust",.viz_NbClust,"factoextra")


fviz_nbclust(res.nbclust, ggtheme = theme_minimal())
#Fixed the function using this:
# https://stackoverflow.com/questions/72075707/rstudio-error-with-the-fviz-nbclust-function
```

* The results tell us that optimal clusters are 3.

### Using 3 clusters

```{r}
# Quality of Clustering

set.seed(123)
# Enhanced hierarchical clustering, cut in 3 groups
res.hc1 <- clg %>% scale() %>%
  eclust("hclust", k = 3, graph = FALSE)

# Visualize with factoextra
fviz_dend(res.hc1, palette = "jco",
          rect = TRUE, show_labels = FALSE)
```

```{r}
fviz_silhouette(res.hc1)
```

### Silhouette width of observations

```{r}
sil <- res.hc1$silinfo$widths[, 1:3]

# Objects with negative silhouette
neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]
```

